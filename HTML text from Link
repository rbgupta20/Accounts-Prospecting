# =============================
# ğŸ“¦ Install dependencies
# =============================
!pip install pandas beautifulsoup4 requests lxml

# =============================
# ğŸ“š Import libraries
# =============================
import pandas as pd
import requests
from bs4 import BeautifulSoup
from google.colab import files

# =============================
# ğŸ“ Step 1 â€“ Upload CSV
# =============================
print("ğŸ“ Upload your CSV containing company links...")
uploaded = files.upload()

file_name = next(iter(uploaded))
df = pd.read_csv(file_name)

# Detect link column automatically
link_column = None
for col in df.columns:
    if "link" in col.lower() or "url" in col.lower():
        link_column = col
        break

if link_column is None:
    raise ValueError("âŒ No column with 'link' or 'url' found.")

print(f"ğŸ”— Using column: {link_column}")

# =============================
# ğŸŒ Step 2 â€“ Extract text using BeautifulSoup
# =============================
def extract_text(url):
    try:
        response = requests.get(
            url,
            timeout=10,
            headers={"User-Agent": "Mozilla/5.0"}
        )
        if response.status_code != 200:
            return f"Error: HTTP {response.status_code}"

        soup = BeautifulSoup(response.text, "lxml")

        # Remove scripts, styles, etc.
        for script in soup(["script", "style", "noscript"]):
            script.extract()

        # Extract visible text
        text = soup.get_text(separator=" ", strip=True)
        return text

    except Exception as e:
        return f"Error: {e}"

# =============================
# ğŸ”„ Step 3 â€“ Process all links
# =============================
results = []

for url in df[link_column]:
    print("â¡ Extracting:", url)
    text = extract_text(url)
    results.append({
        "Company Link": url,
        "Extracted Raw Text": text
    })

# =============================
# ğŸ’¾ Step 4 â€“ Save Output CSV
# =============================
output_df = pd.DataFrame(results)
output_path = "output_text_extracted.csv"
output_df.to_csv(output_path, index=False)

print("âœ… Extraction completed! Downloading file...")
files.download(output_path)
