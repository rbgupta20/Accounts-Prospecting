# =============================
# ğŸ“¦ Install dependencies
# =============================
!pip install pandas beautifulsoup4 requests lxml

# =============================
# ğŸ“š Import libraries
# =============================
importÂ pandas asÂ pd
importÂ requests
fromÂ bs4 importÂ BeautifulSoup
fromÂ google.colab importÂ files

# =============================
# ğŸ“ Step 1 â€“ Upload CSV
# =============================
print("ğŸ“ Upload your CSV containing company links...")
uploaded = files.upload()

file_name = next(iter(uploaded))
df = pd.read_csv(file_name)

# Detect link column automatically
link_column = None
forÂ col inÂ df.columns:
Â  Â  if "link" inÂ col.lower() or "url" inÂ col.lower():
Â  Â  Â  Â  link_column = col
Â  Â  Â  Â  break

ifÂ link_column is None:
Â  Â  raise ValueError("âŒ No column with 'link' or 'url' found.")

print(f"ğŸ”— Using column: {link_column}")

# =============================
# ğŸŒ Step 2 â€“ Extract text using BeautifulSoup
# =============================
def extract_text(url):
Â  Â  try:
Â  Â  Â  Â  response = requests.get(url, timeout=10, headers={
Â  Â  Â  Â  Â  Â  "User-Agent": "Mozilla/5.0"
Â  Â  Â  Â  })
Â  Â  Â  Â  ifÂ response.status_code != 200:
Â  Â  Â  Â  Â  Â  return f"Error: HTTP {response.status_code}"

Â  Â  Â  Â  soup = BeautifulSoup(response.text, "lxml")

Â  Â  Â  Â  # Extract visible text
Â  Â  Â  Â  forÂ script inÂ soup(["script", "style", "noscript"]):
Â  Â  Â  Â  Â  Â  script.extract()

Â  Â  Â  Â  text = soup.get_text(separator=" ", strip=True)
Â  Â  Â  Â  returnÂ text

Â  Â  exceptÂ Exception asÂ e:
Â  Â  Â  Â  return f"Error: {e}"

# =============================
# ğŸ”„ Step 3 â€“ Process all links
# =============================
results = []

forÂ url inÂ df[link_column]:
Â  Â  print("â¡ Extracting:", url)
Â  Â  text = extract_text(url)
Â  Â  results.append({
Â  Â  Â  Â  "Company Link": url,
Â  Â  Â  Â  "Extracted Raw Text": text
Â  Â  })

# =============================
# ğŸ’¾ Step 4 â€“ Save Output CSV
# =============================
output_df = pd.DataFrame(results)
output_path = "output_text_extracted.csv"
output_df.to_csv(output_path, index=False)

print("âœ… Extraction completed! Downloading file...")
files.download(output_path)
